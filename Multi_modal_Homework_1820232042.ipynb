{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfYNIUvk/r2BtX/HcDFhgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SabeehAnsari/Pytorch-Image-classifier/blob/main/Multi_modal_Homework_1820232042.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install torch torchvision torchaudio transformers"
      ],
      "metadata": {
        "id": "2CO0GeTW4-Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Check if CUDA is available (for GPU usage)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_RMfdrU5R1W",
        "outputId": "24b9f5d4-ff3d-46e0-8b1e-265b5c577c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and processor from Hugging Face\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(device)"
      ],
      "metadata": {
        "id": "V_29fMaM5-nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\", use_fast=True)"
      ],
      "metadata": {
        "id": "-rICks-_6Zc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read text from the corresponding text file\n",
        "def read_text_file(text_file_path):\n",
        "    with open(text_file_path, \"r\") as file:\n",
        "        return file.read().strip()"
      ],
      "metadata": {
        "id": "R8sSOE_Z9soM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process images and text and get similarity\n",
        "def process_image_and_text(image_path, text_description):\n",
        "    # Load image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Prepare the image and text for CLIP\n",
        "    inputs = processor(text=text_description, images=image, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # Move inputs to the correct device (GPU or CPU)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Get the model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Calculate the similarity between image and text (logits_per_image)\n",
        "    logits_per_image = outputs.logits_per_image  # Image-text similarity scores\n",
        "    probs = logits_per_image.softmax(dim=1)  # Probabilities for each description\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "HTo9FiTg9voX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder containing your images and text files (adjust this if needed)\n",
        "image_folder = \"/content/Images/\"\n",
        "\n",
        "# List of images and corresponding text files\n",
        "image_paths = [\n",
        "    \"Airplane.jpg\", \"Architecture.jpg\", \"Bird.jpg\", \"Butterfly.jpg\", \"Car.jpg\",\n",
        "    \"Cat.jpg\", \"Child.jpg\", \"Eagle.jpg\", \"Flag.jpg\", \"Ship.jpg\"\n",
        "]\n",
        "\n",
        "text_paths = [\n",
        "    \"Airplane.txt\", \"Architecture.txt\", \"Bird.txt\", \"Butterfly.txt\", \"Car.txt\",\n",
        "    \"Cat.txt\", \"Child.txt\", \"Eagle.txt\", \"Flag.txt\", \"Ship.txt\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "5j0ktT_2-Aj0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each image and generate the best matching description\n",
        "for image_file, text_file in zip(image_paths, text_paths):\n",
        "    # Full paths to images and text files\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    text_path = os.path.join(image_folder, text_file)\n",
        "\n",
        "    # Read the description from the text file\n",
        "    description = read_text_file(text_path)\n",
        "\n",
        "    # Get the probabilities (similarity scores) for the description\n",
        "    probs = process_image_and_text(image_path, description)\n",
        "\n",
        "    # Get the index of the description with the highest similarity\n",
        "    best_description_index = torch.argmax(probs).item()\n",
        "    best_description = description  # In this case, it's the only description, but you can adjust if needed\n",
        "\n",
        "    print(f\"Best description for {image_file}: {best_description}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfCyTE8Q_MkW",
        "outputId": "82e47438-0de5-4a65-cd76-52b537c0ded8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best description for Airplane.jpg: A large commercial airplane on a runway, with its engines roaring and wheels touching the ground, preparing for takeoff under a clear blue sky.\n",
            "\n",
            "Best description for Architecture.jpg: A view of the Colosseum in Rome, Italy, showcasing its ancient Roman architecture with arched windows and stonework, standing proudly against the grey sky.\n",
            "\n",
            "Best description for Bird.jpg: A brightly colored bird with a red head and yellow body perched on a wooden branch, looking towards the camera with its sharp beak slightly open.\n",
            "\n",
            "Best description for Butterfly.jpg: A beautiful butterfly perched delicately on a pink flower, its wings open wide, displaying a bright pattern of orange and black with white spots.\n",
            "\n",
            "Best description for Car.jpg: A silver car captured in motion on a street, with motion blur emphasizing its speed as it moves past the camera.\n",
            "\n",
            "Best description for Cat.jpg: A white cat standing on a wooden ledge, staring curiously ahead with its tail curved, giving a sense of alertness and intrigue in its posture.\n",
            "\n",
            "Best description for Child.jpg: A young child in a blue shirt and brown shorts standing near the shore with a surfboard under his arm, gazing at the sea, ready to hit the waves.\n",
            "\n",
            "Best description for Eagle.jpg: A close-up of a golden eagle, showcasing its sharp beak and piercing eyes, with its feathers detailed and glossy in the sunlight.\n",
            "\n",
            "Best description for Flag.jpg: A vibrant red flag of China, fluttering in the wind against a pale sky, with its five yellow stars clearly visible on the fabric.\n",
            "\n",
            "Best description for Ship.jpg: A close-up of a large, illuminated ship docked at a harbor, with its detailed bow visible, reflecting the soft lights from the ship as it looms over the calm waters of the harbor at dusk.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, torch, pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\").to(device)\n",
        "\n",
        "folder = \"/content/Images\"   # adjust if needed\n",
        "image_glob = sorted(glob.glob(os.path.join(folder, \"*.jpg\")) +\n",
        "                    glob.glob(os.path.join(folder, \"*.JPG\")) +\n",
        "                    glob.glob(os.path.join(folder, \"*.png\")) +\n",
        "                    glob.glob(os.path.join(folder, \"*.PNG\")))\n",
        "\n",
        "rows = []\n",
        "\n",
        "print(\"Found images:\", image_glob)\n",
        "\n",
        "for img_path in image_glob:\n",
        "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    txt_path = os.path.join(folder, f\"{base}.txt\")\n",
        "\n",
        "    if not os.path.exists(txt_path):\n",
        "        print(f\"⚠️ No txt file for {base} → skipping\")\n",
        "        continue\n",
        "\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
        "    if not lines:\n",
        "        print(f\"⚠️ Empty txt file for {base} → skipping\")\n",
        "        continue\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    inputs = processor(text=lines, images=image, return_tensors=\"pt\", padding=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(**inputs)\n",
        "        logits = out.logits_per_image\n",
        "        probs = logits.softmax(dim=1).squeeze(0).cpu().tolist()\n",
        "\n",
        "    best_idx = int(torch.argmax(logits, dim=1).item())\n",
        "    best_text = lines[best_idx]\n",
        "    best_prob = float(probs[best_idx])\n",
        "\n",
        "    rows.append({\n",
        "        \"image\": os.path.basename(img_path),\n",
        "        \"num_candidates\": len(lines),\n",
        "        \"best_text\": best_text,\n",
        "        \"best_prob\": best_prob\n",
        "    })\n",
        "\n",
        "# Only create DataFrame if rows is not empty\n",
        "if rows:\n",
        "    df = pd.DataFrame(rows).sort_values(\"image\")\n",
        "    csv_path = os.path.join(folder, \"clip_results.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\n✅ Saved results → {csv_path}\")\n",
        "    display(df)\n",
        "else:\n",
        "    print(\"\\n⚠️ No results — check file paths and names!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "KIwNqdabDV7g",
        "outputId": "b25e757c-601e-4631-89f0-57d7bffcf29c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found images: ['/content/Images/Airplane.jpg', '/content/Images/Architecture.jpg', '/content/Images/Bird.jpg', '/content/Images/Butterfly.jpg', '/content/Images/Car.jpg', '/content/Images/Cat.jpg', '/content/Images/Child.jpg', '/content/Images/Eagle.jpg', '/content/Images/Flag.jpg', '/content/Images/Ship.jpg']\n",
            "\n",
            "✅ Saved results → /content/Images/clip_results.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              image  num_candidates  \\\n",
              "0      Airplane.jpg               1   \n",
              "1  Architecture.jpg               1   \n",
              "2          Bird.jpg               1   \n",
              "3     Butterfly.jpg               1   \n",
              "4           Car.jpg               1   \n",
              "5           Cat.jpg               1   \n",
              "6         Child.jpg               1   \n",
              "7         Eagle.jpg               1   \n",
              "8          Flag.jpg               1   \n",
              "9          Ship.jpg               1   \n",
              "\n",
              "                                           best_text  best_prob  \n",
              "0  A large commercial airplane on a runway, with ...        1.0  \n",
              "1  A view of the Colosseum in Rome, Italy, showca...        1.0  \n",
              "2  A brightly colored bird with a red head and ye...        1.0  \n",
              "3  A beautiful butterfly perched delicately on a ...        1.0  \n",
              "4  A silver car captured in motion on a street, w...        1.0  \n",
              "5  A white cat standing on a wooden ledge, starin...        1.0  \n",
              "6  A young child in a blue shirt and brown shorts...        1.0  \n",
              "7  A close-up of a golden eagle, showcasing its s...        1.0  \n",
              "8  A vibrant red flag of China, fluttering in the...        1.0  \n",
              "9  A close-up of a large, illuminated ship docked...        1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e1caca2-c70b-4d68-8b61-929f74d9953d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>num_candidates</th>\n",
              "      <th>best_text</th>\n",
              "      <th>best_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Airplane.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A large commercial airplane on a runway, with ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Architecture.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A view of the Colosseum in Rome, Italy, showca...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bird.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A brightly colored bird with a red head and ye...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Butterfly.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A beautiful butterfly perched delicately on a ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Car.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A silver car captured in motion on a street, w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cat.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A white cat standing on a wooden ledge, starin...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Child.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A young child in a blue shirt and brown shorts...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Eagle.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A close-up of a golden eagle, showcasing its s...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Flag.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A vibrant red flag of China, fluttering in the...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ship.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>A close-up of a large, illuminated ship docked...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e1caca2-c70b-4d68-8b61-929f74d9953d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e1caca2-c70b-4d68-8b61-929f74d9953d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e1caca2-c70b-4d68-8b61-929f74d9953d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-10985bb5-9646-41c9-bb61-996a938749f4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10985bb5-9646-41c9-bb61-996a938749f4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-10985bb5-9646-41c9-bb61-996a938749f4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_38966ffc-15ea-43e7-b899-68307c175e30\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_38966ffc-15ea-43e7-b899-68307c175e30 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Flag.jpg\",\n          \"Architecture.jpg\",\n          \"Cat.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_candidates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"A vibrant red flag of China, fluttering in the wind against a pale sky, with its five yellow stars clearly visible on the fabric.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}